{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"state-college-pa.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"pa.osm\"\n",
    "\n",
    "k = 1000 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"state-college-pa.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Alley\", \"Box\", \"Building\", \"Center\", \"Circle\", \"Pike\", \"Way\",\n",
    "           '522']\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Aly\": \"Alley\",\n",
    "           \"Blvd\": \"Boulevard\",\n",
    "           \"Dr\": \"Drive\",\n",
    "           \"Ln\": \"Lane\",\n",
    "           \"Rd\": \"Road\",\n",
    "           \"STreet\": \"Street\",\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    #pprint.pprint(dict(street_types))\n",
    "    return street_types\n",
    "\n",
    "def update_name(name, mapping):   \n",
    "    m = street_type_re.search(name)\n",
    "    if m not in expected:\n",
    "        name = re.sub(m.group(), mapping[m.group()], name)\n",
    "    return name\n",
    "\n",
    "    \n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "multiple_colons = re.compile(r':{2,}')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "#The shape_element function runs on each element\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    address = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        # created dictionary for creation info\n",
    "        created = {}\n",
    "        # pos list for lat and lon\n",
    "        pos = []\n",
    "        node['type'] = element.tag\n",
    "        # loop through each element attribute\n",
    "        for a in element.attrib.keys():\n",
    "            # if key in CREATED list, add key:value to created dictionary\n",
    "            if a in CREATED: \n",
    "                created[a] = element.attrib[a]\n",
    "                # if created dictionary created, add to node dictionary\n",
    "                if created: \n",
    "                    node['created'] = created\n",
    "            # if key is lat or lon, add to pos list, then add list to node dict\n",
    "            elif a == 'lat':\n",
    "                pos.insert(0,element.get('lat'))\n",
    "            elif a == 'lon':\n",
    "                pos.insert(0,element.get('lon'))\n",
    "                node['pos'] = pos\n",
    "            # otherwise, add key:value pair of attribute to node dictionary\n",
    "            else:\n",
    "                node[a] = element.get(a)           \n",
    "        for subtag in element:\n",
    "            if subtag.get('k'):\n",
    "                # if tag has two or more colons, ignore\n",
    "                if re.search(r':.*:', subtag.get('k')):\n",
    "                    continue\n",
    "                #if tag has problem characters, ignore\n",
    "                elif problemchars.search(subtag.get('k')):\n",
    "                    continue\n",
    "                #if tag is for street, check that the street name is in expected,\n",
    "                # if not, change to the value in mapping dictionary\n",
    "                elif subtag.get('k') == 'addr:street':\n",
    "                    m = street_type_re.search(subtag.get('v'))\n",
    "                    if m:\n",
    "                        street_type = m.group()\n",
    "                        if street_type not in expected:\n",
    "                            address['street'] = update_name(subtag.get('v'), mapping)\n",
    "                        else:\n",
    "                            address['street'] = subtag.get('v')\n",
    "                # add all other address values to address dictionary\n",
    "                elif subtag.get('k').startswith('addr:'):\n",
    "                    address[subtag.get('k')[5:]] = subtag.get('v')\n",
    "                else:\n",
    "                    node[subtag.get('k')] = subtag.get('v')\n",
    "                if address:\n",
    "                    node['address'] = address\n",
    "        return node\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        counter = 0\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "            # counter addeded to verify script is still running on larger datasets\n",
    "            counter += 1\n",
    "            if counter % 100000 == 0:\n",
    "                print counter\n",
    "    return data\n",
    "\n",
    "def run():\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    #data = process_map('C:\\Users\\Mister\\Documents\\data_analyst\\P3_Data_Wrangling\\example.osm', True)\n",
    "    data = process_map('state-college-pa.osm', True)\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Street names not in expected list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'Aly': {'McAllister Aly'},\n",
       "             'Ave': {'Delaware Ave',\n",
       "              'E College Ave',\n",
       "              'East Beaver Ave',\n",
       "              'W College Ave',\n",
       "              'W Freedom Ave',\n",
       "              'West Freedom Ave'},\n",
       "             'Blvd': {'Colonnade Blvd'},\n",
       "             'Dr': {'Premiere Dr'},\n",
       "             'Ln': {'Sandy Ln'},\n",
       "             'Rd': {\"McAlevy's Fort Rd\"},\n",
       "             'STreet': {'South Butz STreet'},\n",
       "             'St': {'4th St',\n",
       "              'E Main St',\n",
       "              'Hiester St',\n",
       "              'N Juniata St',\n",
       "              'N Patterson St',\n",
       "              'S Fraser St',\n",
       "              'S Garner St',\n",
       "              'S Hiester St',\n",
       "              'S Sparks St'},\n",
       "             'St.': {'North Atherton St.', 'S. Fraser St.'}})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit('state-college-pa.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "1. In command prompt, cd to C:\\Program Files\\MongoDB\\Server\\3.2\\bin.\n",
    "2. mongo\n",
    "3. db.pa.drop()\n",
    "2. mongoimport -d test -c pa --file C:\\Users\\Mister\\Documents\\data_analyst\\P3_Data_Wrangling\\P3\\state-college-pa.osm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348100"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.pa.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB Stats within MongoDB shell \n",
    "\n",
    "In command window:\n",
    "1. mongo\n",
    "2. show dbs\n",
    "3. show collections\n",
    "4. use test\n",
    "5. coll = db.pa\n",
    "6. coll.find().count()\n",
    "7. coll.dataSize()\n",
    "8. coll.stats()\n",
    "\n",
    "(or \n",
    "db.pa.stats()\n",
    "db.sample.dataSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327544"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.pa.find({'type': 'node'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.pa.find({'type': 'ways'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    }
   ],
   "source": [
    "print len(db.pa.distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/30327508/mongodb-osm-street-maps-unique-users\n",
    "distinct returns a list.  to get the length of a list in python, use length()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 users with highest number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'woodpeck_fixbot', u'count': 206010}\n",
      "{u'_id': u'Sven L', u'count': 82402}\n",
      "{u'_id': u'TIGERcnl', u'count': 8170}\n",
      "{u'_id': u'bot-mode', u'count': 7491}\n",
      "{u'_id': u'DaveHansenTiger', u'count': 4903}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cursor = db.pa.aggregate([\n",
    "        {'$group': {'_id': \"$created.user\", 'count': {'$sum': 1}}},\n",
    "        {'$sort': {'count': -1}},\n",
    "        {'$limit': 5}\n",
    "    ])\n",
    "for doc in cursor:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number and Types of Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 347264}\n",
      "{u'_id': u'yes', u'count': 716}\n",
      "{u'_id': u'apartments', u'count': 57}\n",
      "{u'_id': u'residential', u'count': 21}\n",
      "{u'_id': u'entrance', u'count': 16}\n",
      "{u'_id': u'house', u'count': 9}\n",
      "{u'_id': u'commercial', u'count': 5}\n",
      "{u'_id': u'retail', u'count': 4}\n",
      "{u'_id': u'industrial', u'count': 2}\n",
      "{u'_id': u'collapsed', u'count': 2}\n",
      "{u'_id': u'ruins', u'count': 1}\n",
      "{u'_id': u'public', u'count': 1}\n",
      "{u'_id': u'office', u'count': 1}\n",
      "{u'_id': u'Restaurant', u'count': 1}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cursor = db.pa.aggregate([\n",
    "        {'$group': {'_id': \"$building\", 'count': {'$sum': 1}}},\n",
    "        {'$sort': {'count': -1}}\n",
    "    ])\n",
    "for doc in cursor:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postcode Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'16803', u'16801-9998', u'16801', u'16801-4736', u'16801-3838', u'16801-4922', u'16801-2812', u'16801-4713', u'16802-2604', u'16801-4032', u'16801-2810', u'16801-3923', u'16801-3922', u'16801-3919', u'16823', u'16669', u'16870', u'16801-7307', u'17004', u'16828', u'17841', u'16804', u'16858', u'16802', u'16801-2811', u'16801-3804', u'16827', u'16803-3073', u'16803-3044', u'16801-3896', u'17044', u'17009', u'PA', u'17747']\n"
     ]
    }
   ],
   "source": [
    "print db.pa.distinct('address.postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': None, u'count': 347264}\n",
      "{u'_id': u'yes', u'count': 716}\n",
      "{u'_id': u'apartments', u'count': 57}\n",
      "{u'_id': u'residential', u'count': 21}\n",
      "{u'_id': u'entrance', u'count': 16}\n",
      "{u'_id': u'house', u'count': 9}\n",
      "{u'_id': u'commercial', u'count': 5}\n",
      "{u'_id': u'retail', u'count': 4}\n",
      "{u'_id': u'industrial', u'count': 2}\n",
      "{u'_id': u'collapsed', u'count': 2}\n",
      "{u'_id': u'ruins', u'count': 1}\n",
      "{u'_id': u'public', u'count': 1}\n",
      "{u'_id': u'office', u'count': 1}\n",
      "{u'_id': u'Restaurant', u'count': 1}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cursor = db.pa.aggregate([\n",
    "        {'$group': {'_id': \"$building\", 'count': {'$sum': 1}}},\n",
    "        {'$sort': {'count': -1}}\n",
    "    ])\n",
    "for doc in cursor:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'16801', u'count': 273}\n",
      "{u'_id': u'', u'count': 347772}\n",
      "{u'_id': u'16828', u'count': 1}\n",
      "{u'_id': u'16870', u'count': 1}\n",
      "{u'_id': u'16804', u'count': 1}\n",
      "{u'_id': u'16803', u'count': 26}\n",
      "{u'_id': u'16669', u'count': 1}\n",
      "{u'_id': u'16802', u'count': 7}\n",
      "{u'_id': u'16823', u'count': 3}\n",
      "{u'_id': u'17004', u'count': 1}\n",
      "{u'_id': u'17841', u'count': 1}\n",
      "{u'_id': u'16858', u'count': 5}\n",
      "{u'_id': u'16827', u'count': 2}\n",
      "{u'_id': u'17044', u'count': 2}\n",
      "{u'_id': u'17009', u'count': 2}\n",
      "{u'_id': u'PA', u'count': 1}\n",
      "{u'_id': u'17747', u'count': 1}\n"
     ]
    }
   ],
   "source": [
    "cursor = db.pa.aggregate([\n",
    "        {'$group': {'_id': {'$substr': ['$address.postcode', 0, 5]}, \n",
    "                            'count': {'$sum': 1}}}])\n",
    "for doc in cursor:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'node', u'Public', u'way', u'route']\n"
     ]
    }
   ],
   "source": [
    "print db.pa.distinct('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'natural': u'tree', u'created': {u'changeset': u'35623297', u'version': u'4', u'user': u'woodpeck_repair', u'timestamp': u'2015-11-28T07:12:55Z', u'uid': u'145231'}, u'lon': u'-77.4423822', u'pos': [39.0586388, -77.4423822], u'_id': ObjectId('578d159c87b6d73f4147c126'), u'type': u'broad_leaved', u'id': u'2405872915'}\n",
      "{u'natural': u'tree', u'created': {u'changeset': u'35623297', u'version': u'4', u'user': u'woodpeck_repair', u'timestamp': u'2015-11-28T07:12:55Z', u'uid': u'145231'}, u'pos': [u'39.0586388', u'-77.4423822'], u'_id': ObjectId('579a696de300de16b3497a08'), u'type': u'broad_leaved', u'id': u'2405872915'}\n",
      "{u'natural': u'tree', u'created': {u'changeset': u'35623297', u'version': u'4', u'user': u'woodpeck_repair', u'timestamp': u'2015-11-28T07:12:55Z', u'uid': u'145231'}, u'pos': [u'39.0586388', u'-77.4423822'], u'_id': ObjectId('579e691e757d8f6e3fbdd01b'), u'type': u'broad_leaved', u'id': u'2405872915'}\n",
      "{u'natural': u'tree', u'created': {u'changeset': u'35623297', u'version': u'4', u'user': u'woodpeck_repair', u'timestamp': u'2015-11-28T07:12:55Z', u'uid': u'145231'}, u'pos': [u'39.0586388', u'-77.4423822'], u'_id': ObjectId('579e7a89757d8f6e3fbdd0e5'), u'type': u'broad_leaved', u'id': u'2405872915'}\n"
     ]
    }
   ],
   "source": [
    "cursor = db.sample.find({'type': 'broad_leaved'})\n",
    "for doc in cursor:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Street check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'School Drive', u'S Fraser Street', u'South Allen Street', u'South Pugh Street', u'West College Avenue', u'East College Avenue', u'East Calder Way', u'East Beaver Avenue', u'West Beaver Avenue', u'Food Science Building', u'Transfer Road', u'Premiere Drive', u'South Buckhout Street', u'N Patterson Street', u'South Atherton Street', u'Hiester Street', u'S Hiester Street', u'S Garner Street', u'S Sparks Street', u'North Atherton Street', u'McAllister Alley', u\"McAlevy's Fort Road\", u'Montauk Circle', u'South Burrowes Street', u'South Fraser Street', u'West Calder Way', u'Miller Alley', u'Northland Center', u'Benner Pike', u'E Main Street', u'S. Fraser Street', u'S Atherton Street', u'Houser Road', u'Earlystown Road', u'East Specht Street', u'US 522', u'Post Office Box', u'Pollock Road', u'W College Avenue', u'South Butz Street', u'Boalsburg Pike', u'West Park Avenue', u'Martin Street', u'West Aaron Drive', u'Blue Course Drive', u'Innovation Boulevard', u'John Wert Road', u'The 300 Building', u'Rider Building', u'South Eagle Valley Road', u'N Juniata Street', u'Colonnade Boulevard', u'Delaware Avenue', u'4th Street', u'Sandy Lane', u'W Freedom Avenue', u'E College Avenue', u'West Freedom Avenue', u'Glenlew Drive', u'Boal Avenue', u'Fernwood Court', u'Cricklewood Drive', u'Toftrees Avenue', u'north atherton Street', u'Alaina Drive']\n"
     ]
    }
   ],
   "source": [
    "print db.pa.distinct('address.street')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ammenity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'fountain', u'count': 2}\n",
      "{u'_id': None, u'count': 347278}\n",
      "{u'_id': u'restaurant', u'count': 88}\n",
      "{u'_id': u'place_of_worship', u'count': 96}\n",
      "{u'_id': u'school', u'count': 171}\n",
      "{u'_id': u'toilets', u'count': 6}\n",
      "{u'_id': u'fuel', u'count': 20}\n",
      "{u'_id': u'post_office', u'count': 8}\n",
      "{u'_id': u'grave_yard', u'count': 102}\n",
      "{u'_id': u'parking', u'count': 155}\n",
      "{u'_id': u'hospital', u'count': 8}\n",
      "{u'_id': u'parking_entrance', u'count': 2}\n",
      "{u'_id': u'library', u'count': 3}\n",
      "{u'_id': u'community_centre', u'count': 1}\n",
      "{u'_id': u'pub', u'count': 15}\n",
      "{u'_id': u'cafe', u'count': 13}\n",
      "{u'_id': u'bank', u'count': 20}\n",
      "{u'_id': u'arts_centre', u'count': 1}\n",
      "{u'_id': u'post_box', u'count': 4}\n",
      "{u'_id': u'drinking_water', u'count': 1}\n",
      "{u'_id': u'food_court', u'count': 2}\n",
      "{u'_id': u'recycling', u'count': 4}\n",
      "{u'_id': u'fire_station', u'count': 8}\n",
      "{u'_id': u'fast_food', u'count': 22}\n",
      "{u'_id': u'shelter', u'count': 14}\n",
      "{u'_id': u'public_building', u'count': 5}\n",
      "{u'_id': u'cinema', u'count': 3}\n",
      "{u'_id': u'theatre', u'count': 5}\n",
      "{u'_id': u'bar', u'count': 5}\n",
      "{u'_id': u'clubhouse', u'count': 1}\n",
      "{u'_id': u'police', u'count': 2}\n",
      "{u'_id': u'pharmacy', u'count': 8}\n",
      "{u'_id': u'atm', u'count': 4}\n",
      "{u'_id': u'nightclub', u'count': 2}\n",
      "{u'_id': u'bus_station', u'count': 2}\n",
      "{u'_id': u'vending_machine', u'count': 1}\n",
      "{u'_id': u'bbq', u'count': 2}\n",
      "{u'_id': u'bench', u'count': 4}\n",
      "{u'_id': u'townhall', u'count': 3}\n",
      "{u'_id': u'university', u'count': 1}\n",
      "{u'_id': u'ski_school', u'count': 1}\n",
      "{u'_id': u'prison', u'count': 1}\n",
      "{u'_id': u'swimming_pool', u'count': 3}\n",
      "{u'_id': u'marketplace', u'count': 2}\n",
      "{u'_id': u'veterinary', u'count': 1}\n"
     ]
    }
   ],
   "source": [
    "cursor = db.pa.aggregate([\n",
    "    {'$group': {'_id': \"$amenity\", 'count': {'$sum': 1}}}])\n",
    "    \n",
    "for doc in cursor:\n",
    "    pprint.pprint(doc)\n",
    "\n",
    "#print db.pa.distinct('amenity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
